services:
  pytorch_241:
    build:
      context: .
      dockerfile: .docker/nvidia-cuda-12.4.1-rockylinux8.Dockerfile
    container_name: 'nvidia-docker_241'
    stdin_open: true
    tty: true
    volumes:
      - ./:/app
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    runtime: nvidia
